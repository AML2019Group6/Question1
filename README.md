# Question1
Question 1 Gradient Descent Project

Importance of gradient descent: It is a method which determines how well the machine learning model has performed given the different values of each parameter. In any model, we have the predicted results and the actual results. The difference between these two is known as the error. Imagine there was a mathematical function which represented the error. The objective is to always minimise this error function (so that our model can suitably represent the actual scenario) and often, calculus cannot find the answer to this. Gradient descent aids us in finding the minimum since it is an iterative optimisation algorithm.

Plain vanilla gradient descent: This is the simplest/unmodified form of gradient descent. It involves taking small steps toward the minima by utilising the gradient of the cost function. Imagine we had a valley and two hills on either side in a 2 dimensional setting. Plain vanilla gradient descent involves taking steps downhill toward the valley.

Momentum gradient descent: This is one of the modifications of gradient descent which was incorporated. It considers the past movements before going to the next step. 

RMSprop:

Three hump camel function:


How results vary with step size:



